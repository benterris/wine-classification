{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1452 # for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize= 'spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129976\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "with open('datasets/winemag-data-130k-v2.csv') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38992\n",
      "64988\n",
      "64987\n",
      "38992\n",
      "25996\n",
      "['18579,US,\"Flavors of candied lemon, lime and pineapple are brightened by crisp acidity in this unoaked  Sauvignon Blanc. The wine reflects this cool-climate Monterey appellation with its clean, brisk character.\",,85,16.0,California,Arroyo Seco,Central Coast,,,Mercy 2010 Sauvignon Blanc (Arroyo Seco),Sauvignon Blanc,Mercy\\n', '89421,US,\"There\\'s a lot of oak on this Chardonnay, to judge by the buttered toast and butterscotch richness. Underneath all that is a wine ripe in tropical fruits and green apples, brightened by excellent, mouthwatering acidity. The oak stands out now, but give the wine until 2015 or 2016 in the cellar to let the parts integrate.\",Sierra Mar Vineyard,90,40.0,California,Santa Lucia Highlands,Central Coast,,,Loring Wine Company 2012 Sierra Mar Vineyard Chardonnay (Santa Lucia Highlands),Chardonnay,Loring Wine Company\\n', '56113,US,\"Almost mauve in color, this widely distributed wine (named after the time the winemaking crew pops open their bottles at home) shows candied strawberry, watermelon Jolly Rancher and a touch of slate on the nose. Tons of tongue-tingling acidity and a expertly grippy texture cut through the watermelon and raspberry flavors.\",515 Vine Select,89,15.0,California,Central Coast,Central Coast,Matt Kettmann,@mattkettmann,Noble Vines 2016 515 Vine Select Rosé (Central Coast),Rosé,Noble Vines\\n']\n"
     ]
    }
   ],
   "source": [
    "# Split in train and test\n",
    "# @Pierre: en fait on utilisera plutot le split de torchtext (voir plus bas)\n",
    "\n",
    "TEST_SET_SIZE = .3\n",
    "VALIDATION_SET_SIZE = .2\n",
    "\n",
    "indices = list(range(1, len(lines)))\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "first_split_index = int(TEST_SET_SIZE * len(lines))\n",
    "second_split_index = int((TEST_SET_SIZE+VALIDATION_SET_SIZE) * len(lines))\n",
    "\n",
    "print(first_split_index)\n",
    "print(second_split_index)\n",
    "\n",
    "test_indices = indices[:first_split_index]\n",
    "validation_indices = indices[first_split_index:second_split_index]\n",
    "train_indices = indices[second_split_index:]\n",
    "\n",
    "train_set = [lines[k] for k in train_indices]\n",
    "test_set = [lines[k] for k in test_indices]\n",
    "validation_set = [lines[k] for k in validation_indices]\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(validation_set))\n",
    "print(train_set[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write split sets\n",
    "with open('preprocessed_datasets/train.csv', 'w') as train_file:\n",
    "    train_file.write(''.join(train_set))\n",
    "with open('preprocessed_datasets/test.csv', 'w') as test_file:\n",
    "    test_file.write(''.join(test_set))\n",
    "with open('preprocessed_datasets/validation.csv', 'w') as validation_file:\n",
    "    validation_file.write(''.join(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess json\n",
    "# (torchtext needs a file with a new json record per row and not a proper json)\n",
    "import json\n",
    "with open('datasets/winemag-data-130k-v2.json') as f:\n",
    "    jsonfile = json.loads(f.read())\n",
    "res = ''\n",
    "# print(str(jsonfile[0]))\n",
    "# print(json.dumps(jsonfile[0]))\n",
    "for record in jsonfile:\n",
    "    res += json.dumps(record) + '\\n'\n",
    "\n",
    "# print(res[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write preprocessed json to new file\n",
    "with open('testfile', 'w') as out:\n",
    "    out.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'TabularDataset' has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-20c7f12e663a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/wineClassification/env/lib/python3.5/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36msplits\u001b[0;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         train_data = None if train is None else cls(\n\u001b[1;32m     78\u001b[0m             os.path.join(path, train), **kwargs)\n",
      "\u001b[0;32m~/wineClassification/env/lib/python3.5/site-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(cls, root, check)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TabularDataset' has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Setup a dataset from the preprocessed json\n",
    "full_dataset = data.TabularDataset(\n",
    "    path='testfile',\n",
    "    format='json',\n",
    "    fields={'description': ('description', data.Field(sequential=True)),\n",
    "            'points': ('points', data.Field(sequential=False))}\n",
    ")\n",
    "\n",
    "a,b = full_dataset.splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'points': '87', 'description': ['Aromas', 'include', 'tropical', 'fruit,', 'broom,', 'brimstone', 'and', 'dried', 'herb.', 'The', 'palate', \"isn't\", 'overly', 'expressive,', 'offering', 'unripened', 'apple,', 'citrus', 'and', 'dried', 'sage', 'alongside', 'brisk', 'acidity.']}\n",
      "63686\n",
      "38991\n",
      "27294\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(vars(full_dataset.examples[0]))\n",
    "train_and_valid_data, test_data = full_dataset.split(random_state = random.seed(SEED))\n",
    "\n",
    "train_data, valid_data = train_and_valid_data.split(random_state = random.seed(SEED))\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 : build the dataset\n",
    "tv_datafields = [(\"id\", None),\n",
    "                 (\"country\", LABEL),\n",
    "                 (\"description\", TEXT),\n",
    "                 (\"designation\", LABEL),\n",
    "                 (\"points\", LABEL),\n",
    "                 (\"price\", LABEL),\n",
    "                 (\"province\", LABEL),\n",
    "                 (\"region_1\", LABEL),\n",
    "                 (\"region_2\", LABEL),\n",
    "                 (\"taster_name\", LABEL),\n",
    "                 (\"taster_twitter_handle\", LABEL),\n",
    "                 (\"title\", LABEL),\n",
    "                 (\"variety\", LABEL),\n",
    "                 (\"winery\", LABEL)]\n",
    "\n",
    "trn, vld, tst = data.TabularDataset.splits(path='preprocessed_datasets',\n",
    "                                     format=\"csv\",\n",
    "                                     train= 'train.csv',\n",
    "                                     validation='validation.csv',\n",
    "                                     test='test.csv',\n",
    "                                     fields=tv_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25002\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "TEXT.build_vocab(trn, max_size=MAX_VOCAB_SIZE)\n",
    "\n",
    "print(len(TEXT.vocab))\n",
    "# 25002 because of <pad> and <unk>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 219889), ('.', 176716), ('and', 173574), ('of', 86268), ('the', 83922), ('a', 78846), ('with', 58105), ('is', 48536), ('wine', 40263), ('-', 37447), ('this', 36671), ('in', 30410), ('flavors', 30207), ('to', 27836), ('The', 26309), (\"'s\", 25712), ('fruit', 24835), ('It', 21974), ('on', 21537), ('it', 21082), ('This', 20352), ('that', 19700), ('palate', 19116), ('aromas', 17736), ('finish', 17409), ('acidity', 17309), ('tannins', 15241), ('from', 15112), ('but', 14779), ('cherry', 14363), ('black', 13894), ('are', 12808), ('ripe', 12598), ('has', 12303), ('A', 10872), ('red', 10620), ('by', 10392), ('for', 10382), ('Drink', 10212), ('%', 9635), ('spice', 9513), ('notes', 9270), ('oak', 8602), ('as', 8533), ('berry', 8463), ('nose', 8392), ('its', 8258), ('rich', 8143), ('an', 7980), ('fresh', 7963), ('dry', 7845), ('now', 7583), ('full', 7419), ('plum', 7346), ('fruits', 6724), ('apple', 6607), ('blend', 6563), ('well', 6561), ('sweet', 6509), ('white', 6268), ('offers', 6238), ('texture', 6233), ('blackberry', 6143), ('soft', 6122), ('crisp', 5982), ('bodied', 5756), ('through', 5744), ('citrus', 5720), ('dark', 5572), ('light', 5469), ('Cabernet', 5434), ('vanilla', 5395), ('shows', 5255), ('while', 4988), ('more', 4947), ('drink', 4908), ('bright', 4899), ('pepper', 4866), ('at', 4750), ('fruity', 4693), ('green', 4629), ('raspberry', 4599), ('juicy', 4511), ('lemon', 4510), ('very', 4377), ('good', 4363), ('firm', 4301), ('chocolate', 4270), ('peach', 4263), ('some', 4249), ('touch', 4232), ('character', 4171), ('balanced', 4103), ('will', 4017), ('out', 3906), ('There', 3895), ('like', 3891), ('Sauvignon', 3889), ('up', 3867), ('pear', 3859)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 : building the iterator\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (trn, vld),\n",
    " batch_sizes=(64, 64),\n",
    " sort_key=lambda x: len(x.description),\n",
    " sort_within_batch=False,\n",
    " repeat=False\n",
    ")\n",
    "\n",
    "test_iter = Iterator(tst, batch_size=64, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5 : Wrapper (obscur)\n",
    "class BatchWrapper:\n",
    "      def __init__(self, dl, x_var, y_vars):\n",
    "            self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x &amp;amp;amp;amp;lt;g class=\"gr_ gr_3178 gr-alert gr_spell gr_inline_cards gr_disable_anim_appear ContextualSpelling ins-del\" id=\"3178\" data-gr-id=\"3178\"&amp;amp;amp;amp;gt;and y&amp;amp;amp;amp;lt;/g&amp;amp;amp;amp;gt;\n",
    "  \n",
    "      def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                  x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "  \n",
    "                  if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                        y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "                  else:\n",
    "                        y = torch.zeros((1))\n",
    "                  yield (x, y)\n",
    "  \n",
    "      def __len__(self):\n",
    "            return len(self.dl)\n",
    " \n",
    "train_dl = BatchWrapper(train_iter, \"description\", [\n",
    "    \"country\",\n",
    "    \"designation\",\n",
    "    \"points\",\n",
    "    \"price\",\n",
    "    \"province\",\n",
    "    \"region_1\",\n",
    "    \"region_2\",\n",
    "    \"taster_name\",\n",
    "    \"taster_twitter_handle\",\n",
    "    \"title\",\n",
    "    \"variety\",\n",
    "    \"winery\"\n",
    "])\n",
    "valid_dl = BatchWrapper(val_iter, \"description\", [\n",
    "    \"country\",\n",
    "    \"designation\",\n",
    "    \"points\",\n",
    "    \"price\",\n",
    "    \"province\",\n",
    "    \"region_1\",\n",
    "    \"region_2\",\n",
    "    \"taster_name\",\n",
    "    \"taster_twitter_handle\",\n",
    "    \"title\",\n",
    "    \"variety\",\n",
    "    \"winery\"\n",
    "])\n",
    "test_dl = BatchWrapper(test_iter, \"description\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4576,  1271,  6818,  ...,    22,    22, 22698],\n",
       "         [   13,    11,    25,  ...,   713,     9, 22196],\n",
       "         [  186,     0,     5,  ...,    61,     7,     9],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wineproject",
   "language": "python",
   "name": "wineproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
