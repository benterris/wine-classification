{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine classification project\n",
    "\n",
    "This is a NLP and deep learning project using `spacy`, `pytorch` and `torchtext`, aiming to retrieve information about a wine based on short text reviews, written by a taster.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The data we're looking to guess are the **country** of production, the  **province** of production, and the **grape variety**.  \n",
    "As a side objective, we show that on this dataset we can retrieve with a great accuracy the **name of the taster**, only from a review they have written.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset contain data scraped from [WineEnthusiast](https://www.winemag.com/?s=&drink_type=wine), and is hosted on [this kaggle page](https://www.kaggle.com/zynicide/wine-reviews#winemag-data-130k-v2.csv). Each example contains a written review of a wine, an various data about this wine like the country and province of production, the grape variety, the winery, the name and twitter handle of the taster, a general grade and a price index.\n",
    "\n",
    "## What we'll do\n",
    "\n",
    "We'll perform the following steps: \n",
    "- Load and clean the data\n",
    "- Setup the training, validation and testing datasets\n",
    "- Setup pre-trained word embeddings\n",
    "- Create a CNN to classify our data\n",
    "- Write a training routine\n",
    "- Test our model\n",
    "\n",
    "In appendix, you'll also find:\n",
    "- Helpers to analysis our model performance and diagnose misclassifications\n",
    "- Our initial RNN implementation, which was not performing as well as our CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 2753 # We always use the same seed for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(\n",
    "    tokenize= 'spacy'\n",
    "#     include_lengths=True # Uncomment for RNN (see appendix)\n",
    ")\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load `torch` and `torchtext`, and setup our fields for `torchtext`. Note that we indicate we're going to use `spacy` as our tokenizer. You need to have spacy installed for this to work, as well as downloading an english language model. `torchtext` expects this model to be called `en`, so you might have to rename it.\n",
    "\n",
    "### Load and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1277 rows\n",
      "Number of classes before cutting: 44\n",
      "Original number of rows: 129909\n",
      "Rows after cutting: 128632\n",
      "Labels kept: ['Italy', 'Portugal', 'US', 'Spain', 'France', 'Germany', 'Argentina', 'Chile', 'Australia', 'Austria', 'South Africa', 'New Zealand', 'Israel', 'Greece', 'Canada']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "CURRENT_LABEL = 'country' # Column we're currently trying to guess. Change this to any of the above columns.\n",
    "\n",
    "# String to int relation between column name and column index, to access them easily\n",
    "COLUMNS_STOI = {\n",
    "    'country': 1, \n",
    "    'province': 6, \n",
    "    'taster_name': 9,\n",
    "    'variety': 12,\n",
    "}\n",
    "\n",
    "MIN_SAMPLE_NUMBER = 150\n",
    "\n",
    "column_number = COLUMNS_STOI[CURRENT_LABEL]\n",
    "\n",
    "with open('datasets/winemag-data-130k-v2.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lines_uncontrolled = []\n",
    "    counts = {}\n",
    "\n",
    "    for row in reader:\n",
    "        if not row[column_number]:\n",
    "            # Skip the row if it doesn't have the current label\n",
    "            continue\n",
    "        if CURRENT_LABEL == 'province':\n",
    "            # Fix the issue where \"Bordeaux\" is also sometimes called \"Burgundy\" (they are the same thing)\n",
    "            if province == \"Burgundy\":\n",
    "                row[6] = \"Bordeaux\"\n",
    "        # Keep a count of each label occurence\n",
    "        if not row[column_number] in counts.keys():\n",
    "            counts[row[column_number]] = 1\n",
    "        else:\n",
    "            counts[row[column_number]] += 1\n",
    "        lines_uncontrolled.append(row)\n",
    "        \n",
    "lines = []\n",
    "\n",
    "# Remove the rows where the label is too rare\n",
    "for row in lines_uncontrolled:\n",
    "    if counts[row[column_number]] >= MIN_SAMPLE_NUMBER:\n",
    "        lines.append(row)\n",
    "    \n",
    "                      \n",
    "print(\"Removed \" + str(len(lines_uncontrolled) - len(lines)) + \" rows\")\n",
    "\n",
    "print(\"Number of classes before cutting:\", len(counts.keys()))\n",
    "print(\"Original number of rows:\", len(lines_uncontrolled))    \n",
    "print(\"Rows after cutting:\", len(lines))\n",
    "print(\"Classes kept:\", [k for k in counts.keys() if counts[k] >= MIN_SAMPLE_NUMBER])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset sometimes lacks data, so we need to make sure we only select the rows where the data we're looking at is present. We also want to keep only the examples for which we have enough data : for instance, if a variety is too rare in the dataset, we won't be able to determine rules to understand what this variety consists in. We can finetune the threshold with `MIN_SAMPLE_NUMBER`. We set it to `150`, which is `1/1000` of the total dataset size.\n",
    "\n",
    "### Train, validation and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 64315\n",
      "Validation set size: 25727\n",
      "Test set size: 38589\n",
      "Train set sample: ['93313', 'US', 'A pleasant sipper for drinking now, with citrus fruit, Asian-pear and peach flavors, accented by acidity. This 100% Sauvignon was unoaked.', 'Honker Blanc', '86', '15.0', 'California', 'Napa Valley', 'Napa', '', '', 'Tudal 2012 Honker Blanc White (Napa Valley)', 'White Blend', 'Tudal']\n"
     ]
    }
   ],
   "source": [
    "TEST_SET_SIZE = .3\n",
    "VALIDATION_SET_SIZE = .2\n",
    "\n",
    "indices = list(range(1, len(lines)))\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "first_split_index = int(TEST_SET_SIZE * len(lines))\n",
    "second_split_index = int((TEST_SET_SIZE+VALIDATION_SET_SIZE) * len(lines))\n",
    "\n",
    "test_indices = indices[:first_split_index]\n",
    "validation_indices = indices[first_split_index:second_split_index]\n",
    "train_indices = indices[second_split_index:]\n",
    "\n",
    "train_set = [lines[k] for k in train_indices]\n",
    "test_set = [lines[k] for k in test_indices]\n",
    "validation_set = [lines[k] for k in validation_indices]\n",
    "\n",
    "print(\"Train set size:\", len(train_set))\n",
    "print(\"Validation set size:\", len(validation_set))\n",
    "print(\"Test set size:\", len(test_set))\n",
    "print(\"Train set sample:\", train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset in train, validation and test. We choose the size of the validation dataset to be 20% of the total size, and the test set to be 30%, leaving 50% for the training.\n",
    "\n",
    "We then write these sets to csv files so we can load them afterwards. Note that we're using the `csv` library to write, because our wine reviews contain commas, so we need to be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir('preprocessed_datasets')\n",
    "except OSError:\n",
    "    # It means the directory already exists, so let's just continue\n",
    "    pass\n",
    "    \n",
    "\n",
    "with open('preprocessed_datasets/train.csv', 'w') as train_file:\n",
    "    writer = csv.writer(train_file)\n",
    "    writer.writerows(train_set)\n",
    "    \n",
    "with open('preprocessed_datasets/test.csv', 'w') as test_file:\n",
    "    writer = csv.writer(test_file)\n",
    "    writer.writerows(test_set)\n",
    "with open('preprocessed_datasets/validation.csv', 'w') as validation_file:\n",
    "    writer = csv.writer(validation_file)\n",
    "    writer.writerows(validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the datasets\n",
    "\n",
    "Then we'll setup the datasets so they can be used by `torchtext`. Here, we tell the library what the lines contains, and what data we want to use. We can select here the label we want to be working on, by setting it to `LABEL`, otherwise we leave it to `None`.\n",
    "\n",
    "The `description` field, which contains the reviews, will always be set to `TEXT`: this is the field on which we're going to do some NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the label you want to predict as `LABEL`, all the other ones to `None`.\n",
    "tv_datafields = [(\"id\", None),\n",
    "                 (\"country\", LABEL),\n",
    "                 (\"description\", TEXT),\n",
    "                 (\"designation\", None),\n",
    "                 (\"points\", None),\n",
    "                 (\"price\", None),\n",
    "                 (\"province\", None),\n",
    "                 (\"region_1\", None),\n",
    "                 (\"region_2\", None),\n",
    "                 (\"taster_name\", None),\n",
    "                 (\"taster_twitter_handle\", None),\n",
    "                 (\"title\", None),\n",
    "                 (\"variety\", None),\n",
    "                 (\"winery\", None)]\n",
    "\n",
    "trn, vld, tst = data.TabularDataset.splits(path='preprocessed_datasets',\n",
    "                                     format=\"csv\",\n",
    "                                     train= 'train.csv',\n",
    "                                     validation='validation.csv',\n",
    "                                     test='test.csv',\n",
    "                                     fields=tv_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup word embedding\n",
    "\n",
    "Now we'll use pretrained word embeddings to improve the accuracy and speed up the training of our models.  \n",
    "We'll build ourselves a vocabulary of the words encountered in the reviews (and in the labels), but as the reviews are quite big, we'll only keep the words common enough. For this we can set a limit on the number of words in our vocabulary. This is not necessary for the labels, because the vocabulary for them is much smaller.\n",
    "\n",
    "**Beware :** `glove.6B.100d` is a library of pretrained vectors. It weights around **800M** and if you don't have it installed, running the following cell will download it. Make sure you have a good connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews vocab length: 25002\n",
      "Labels vocab length: 15\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(trn,\n",
    "                 max_size=MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",  # CAREFUL: this will download ~800M of data\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "print(\"Reviews vocab length:\", len(TEXT.vocab))\n",
    "print(\"Labels vocab length:\", len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we get `25 002` and not `25 000` as our TEXT vocab lenght. This is because `torchtext` adds two reserved tokens: it replaces the word out of our vocab with a `<unk>` (unknown) token, and adds padding so the samples are all the same size with a `<pad>` token.\n",
    "\n",
    "We can check the most common words in our reviews vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 217968), ('.', 174982), ('and', 171656), ('of', 84962), ('the', 83328), ('a', 78092), ('with', 57268), ('is', 48333), ('wine', 39836), ('-', 37121), ('this', 36172), ('in', 30052), ('flavors', 29509), ('to', 27829), ('The', 26060), (\"'s\", 25579), ('fruit', 24629), ('It', 21558), ('on', 21247), ('it', 21153), ('This', 20348), ('that', 19620), ('palate', 19021), ('aromas', 17499), ('acidity', 17096), ('finish', 17009), ('tannins', 15116), ('from', 14883), ('but', 14649), ('cherry', 14086)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the most common word is a comma, which explains why we had to be careful with our csv reading and writing.\n",
    "\n",
    "Now we'll setup iterators, which will allow us to iterate through batches of our training, validation and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # If you have cuda support, this will make sure you're using if for training\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (trn, vld, tst), \n",
    "    batch_size = BATCH_SIZE,\n",
    "#     sort_within_batch=True, # Uncomment for RNN (see appendix), because batches need to be sorted\n",
    "    sort_key=lambda x: len(x.description), \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we sort our data according to the length of the review. This is because we need to add some padding to the reviews to make sure all the samples in a batch are of the same size. Gathering samples of same size close together will ensure we won't have to add too much padding, which will speed up the process a bit.\n",
    "\n",
    "### Creating the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        text = text.permute(1, 0)        \n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__` function we define the architecture of our model. \n",
    "- First we have an **embedding layer** (our input vectors are one-hot vector and are sparse, this will turn them into smaller, non-sparse vector)\n",
    "- Several **convolution layers** : convolution on text is a bit specific, we wrote a little bit more about it in our pdf (in French). Basically, it performs convolution a bit like we would do on images, but instead of layers we use n-grams. Then they all use **ReLU** as an activation function, and then use **max pooling**.\n",
    "- Finally a **linear layer**, of same output size as our number of classes, so we can perform classification\n",
    "- Note we're using **dropout**: this is a technique to avoid overfitting, by randomly setting some node to 0 at each forward pass.\n",
    "\n",
    "Next we'll have to choose the parameters of this architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMENSION = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIMENSION, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `INPUT_DIM` and `OUTPUT_DIM` are based on our data.\n",
    "- The embedding dimension `EMBEDDING_DIM` is fixed by the pretrained data we've loaded, so we have to keep this one at 100.\n",
    "- We can choose `N_FILTER` and `FILTER_SIZES` freely, as well as the dropout rate `DROUPOUT`.\n",
    "\n",
    "We can now use our pre-trained embeddings to setup initial values in our embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3460,  0.7065,  0.1639,  ..., -1.4077,  1.7792, -0.9527],\n",
       "        [-0.9241, -1.4135, -0.8655,  ...,  0.0169, -0.8565, -0.1619],\n",
       "        [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
       "        ...,\n",
       "        [-0.4288, -0.0500, -0.3499,  ..., -1.2627,  0.1444, -0.8879],\n",
       "        [-1.0038,  0.6452, -0.3984,  ..., -0.6172, -0.0960,  0.2449],\n",
       "        [ 0.3714, -1.2620, -0.1996,  ..., -0.2593,  1.2749,  1.0969]])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the pretrained vectors did not contain the `<unk>` and `<pad>` tokens, so we assign them all-zeros token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now we have everything defined, we can train our model.\n",
    "\n",
    "We choose Adam as our optimizer (the nice thing about Adam is that we don't have to select a learning rate, as we would need with stochastic gradient descent).  \n",
    "We also need to choose a loss function. Here we use `CrossEntropyLoss` from `pytorch`, which is for when a sample belongs to exclusively one class (this is our case, as each wine only belongs to one country, one province, has only one writer...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define an accuracy function. As we are doing multi-class classification, we can use the proportion of correctly classified samples in a batch, in other words: on each sample, we choose the label with the max probability, and then we check on the batch what is the proportion of correctly classified labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our training and evaluating functions, which will repectively train the model and evaluate accuracy batch after batch.\n",
    "\n",
    "We are always using the `description` field (review text) as an input, but we can take varying outputs depending on what label we're experimenting on, so we need to get this one back with `getattr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.description)\n",
    "        \n",
    "        loss = criterion(predictions, getattr(batch, CURRENT_LABEL))\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, getattr(batch, CURRENT_LABEL))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.description)\n",
    "            \n",
    "            loss = criterion(predictions, getattr(batch, CURRENT_LABEL))\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, getattr(batch, CURRENT_LABEL))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a helper function to keep track of time during training, so we can compare how fast our different models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to run the training!\n",
    "\n",
    "We choose the number of epochs we want to run the model on, and when we get better results, we save the model in a separate file to make sure we don't lose it as this step can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.02 | Epoch Time: 1m 23s\n",
      "\tTrain Loss: 1.0312679250738515 | Train Acc: 68.61107597896708%\n",
      "\tVal. Loss: 0.6479807856367595 |  Val. Acc: 78.97497878145816%\n",
      "Epoch: 2.02 | Epoch Time: 1m 43s\n",
      "\tTrain Loss: 0.6399591669810946 | Train Acc: 79.38793848403057%\n",
      "\tVal. Loss: 0.5278927133376918 |  Val. Acc: 82.23280917056164%\n",
      "Epoch: 3.02 | Epoch Time: 1m 50s\n",
      "\tTrain Loss: 0.5153121326100174 | Train Acc: 82.79821760025784%\n",
      "\tVal. Loss: 0.4710242266011475 |  Val. Acc: 84.09052209474555%\n",
      "Epoch: 4.02 | Epoch Time: 1m 47s\n",
      "\tTrain Loss: 0.4371247465782498 | Train Acc: 84.90787587355618%\n",
      "\tVal. Loss: 0.45896594141104924 |  Val. Acc: 84.39764224771244%\n",
      "Epoch: 5.02 | Epoch Time: 1m 47s\n",
      "\tTrain Loss: 0.38324987962471313 | Train Acc: 86.60134180861327%\n",
      "\tVal. Loss: 0.43887938610949917 |  Val. Acc: 85.26816562337068%\n",
      "Epoch: 6.02 | Epoch Time: 1m 49s\n",
      "\tTrain Loss: 0.3407266934490322 | Train Acc: 87.95163483168949%\n",
      "\tVal. Loss: 0.45016990779940763 |  Val. Acc: 85.4316586730492%\n",
      "Epoch: 7.02 | Epoch Time: 1m 45s\n",
      "\tTrain Loss: 0.304453016098459 | Train Acc: 89.29789611356176%\n",
      "\tVal. Loss: 0.4400694347473223 |  Val. Acc: 85.69201364446042%\n",
      "Epoch: 8.02 | Epoch Time: 1m 35s\n",
      "\tTrain Loss: 0.2720460459552891 | Train Acc: 90.19328674273704%\n",
      "\tVal. Loss: 0.4695978483268574 |  Val. Acc: 85.54048951882035%\n",
      "Epoch: 9.02 | Epoch Time: 1m 36s\n",
      "\tTrain Loss: 0.24848960844141926 | Train Acc: 91.10396112375592%\n",
      "\tVal. Loss: 0.45912092870370075 |  Val. Acc: 86.07674672532437%\n",
      "Epoch: 10.02 | Epoch Time: 1m 40s\n",
      "\tTrain Loss: 0.2252374086918226 | Train Acc: 91.79180896104272%\n",
      "\tVal. Loss: 0.46924317709693864 |  Val. Acc: 86.01085594044396%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'wine-prediction-model.pt')\n",
    "    \n",
    "    print('Epoch: ' + str(epoch+1) + ' | Epoch Time: ' + str(epoch_mins) + 'm '+ str(epoch_secs) + 's')\n",
    "    print('\\tTrain Loss: ' + str(train_loss) + ' | Train Acc: ' + str(train_acc*100) + '%')\n",
    "    print('\\tVal. Loss: ' + str(valid_loss) + ' |  Val. Acc: ' + str(valid_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the results\n",
    "\n",
    "Now we have trained the model, we can use the test samples we have left aside to test its perfomance on unknown samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4363667101384593 | Test Acc: 85.35604932612645%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('wine-prediction-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print('Test Loss: ' + str(test_loss) + ' | Test Acc: '+ str(test_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the experiment you're running, you can get various results at this step. We kept in our pdf a track of the results we could obtain here.\n",
    "\n",
    "### Live testing\n",
    "\n",
    "To play a bit more with the model, we can use `spacy` to classify in live some reviews :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_class(model, sentence, min_len = 4):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "    return max_preds.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, you can put any review in the description, and check how the model classifies it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is: 0 = Pinot Noir\n"
     ]
    }
   ],
   "source": [
    "description = \"This cooperative, based in Aÿ, has benefited from the fine Pinot Noir in the village to produce a ripe red fruited wine. With balanced acidity and a soft aftertaste, it is ready to drink.\"\n",
    "pred_class = predict_class(model, description)\n",
    "print('Predicted class is: ' + str(pred_class) + ' = ' + str(LABEL.vocab.itos[pred_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "We also provide a few things that are not directly linked to our results above but we used during our work.  \n",
    "\n",
    "### Results exploration\n",
    "\n",
    "To check how our model was performing, as especially in what cases it didn't perform well, we used the following script. It allows us to see a number of wrongly classified samples. This is for instance how we found out that **Burgundy** was also called **Bordeaux** in the dataset, which led to lots of classification errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pure impression ripe Golden Delicious apples shows on the nose of this wine, while the palate majors in citrus. Dry and fresh, it offers tingling zestiness with a pleasantly bitter edge. The dry finish lasts, leaving you to savor apple, zest and something less tangible—perhaps earth or stone. Drink now until 2030.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "Starts out odd and exotic, with blueberry and Middle Eastern spice aromas. Feels condensed and jammy, with full flavors of herbs, boysenberry and plum. Shows freshness along with simplicity, with finishing herbal notes of sage and tarragon. Contains 10% each Merlot and Cabernet.\n",
      "Actual: Spain, predicted: Spain\n",
      "\n",
      "Vine Cliff consistently produces one of the best Chardonnays in Napa Valley, and here's another one. The cool vintage gives it refreshing acidity, while the flavors are ripe and frankly delicious, suggesting pineapple and Key lime pie, vanilla custard, buttered toast, vanilla and dusty pie spices. A girding of minerality helps the dry structure. Really complex, and a joy to drink.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Smoky mineral tones and a racy, acidic edge lend structure to this dry, full-bodied Riesling. Crisp green apple and lemon flavors are mouthwatering and juicy, leading to a pleasantly bitter lime pith finish. Enjoy now through 2025.\n",
      "Actual: Germany, predicted: Germany\n",
      "\n",
      "Baked apple and pressed white flower aromas take center stage on this structured white. The apple sensation follows through to the palate, along with nectarine, Mediterranean herb and a hint of nut. Bright acidity adds freshness.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "Aromas of underbrush, espresso and toasted oak carry over to the palate along with raw red berry. But there's not enough fruit richness to stand up to the astringent tannins and racy acidity.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "This soft wine is ripe and creamy. With fruit mainly from the southern Burgundy, it offers warm apricot and spice flavors. As a contrast, the zesty texture adds a crisp aftertaste. Drink now.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "This lively Pinot Grigio from northern Italy has green apple, ripe pear and citrus sensations alongside fresh acidity. Sip as an apéritif or pair it with summer salads.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "Strawberry and a rich streak of raspberry liqueur play nice in this fresh, zesty Pinot. Tight with tension on the palate, it also features layers of earthy forest-floor mushroom. Big in style, it comes together nicely and makes for an enjoyable wine.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Plum, currant and spice aromas are cool and lightly herbal. A bright, juicy palate delivers robust berry, plum and spice flavors. Dry, complex and harmonious on the finish, this is a shining example from a tough vintage. Drink this blend of 75% Tempranillo and 25% Merlot through 2020.\n",
      "Actual: Spain, predicted: Spain\n",
      "\n",
      "This blend of Chardonnay, Sémillon and Roussanne brings notes of lees, honeycomb and dried apricot. It's medium bodied and creamy in feel, bringing plenty of appeal and going down easy with abundant lees flavors.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Plum and currant aromas are supported by asphalt, dried leather, herbal hints and grit on the bouquet. The palate is full, ripe and steady, while flavors of currant and wild berry are peppery and spicy. An elegant, lightly toasted finish is what this fine Cabernet deserves and delivers. Drink through 2022.\n",
      "Actual: Chile, predicted: Chile\n",
      "\n",
      "This is what vineyard selection and winemaker intervention can do to enrich a wine.  Everything here is on steroids.  The fruit is deep and rich, the oak is smoky and spicy and the finish long and deep.  Pretty fancy stuff that might even improve with a few years in the cellar.\n",
      "Actual: Chile, predicted: US\n",
      "\n",
      "A bright bouquet of floral extract and fine bath oil lays down the carpet for a well-balanced, highly expressive set of white-flower, lychee, lime and honeyed flavors. A full layered finish flows nicely. This is fine Spanish Moscatel.\n",
      "Actual: Spain, predicted: Italy\n",
      "\n",
      "This Pinot is from the winery's only Eola-Amity Hills AVA vineyard. The palate brings distinctive herbal accents around brambly berry-fruit flavors. Rich seams of caramel and chocolate smooth the finish.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Now firmly in its new cellars, Clerc-Milon's wine is performing at the top of its form. This is a dense wine with juicy acidity as well as sweet tannins and ripe blackberry fruits. They give a ripe wine that is finely structured. The juicy aftertaste, typical of this vintage, is appealing although it does not detract from its power and longevity. Drink from 2022.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "This Cabernet Sauvignon is already approachable. It's full bodied and supple, showing a little lightening at the rim. Cherry, earth and herbal notes take on hints of anise and chocolate on the finish. Drink now–2020.\n",
      "Actual: Australia, predicted: Australia\n",
      "\n",
      "Without doubt the most full and complete Chardonnay from Argentina that this critic has tried. It smells lush and toasty, with elegant apple and pear aromas. The mouthfeel is rich and balanced, while flavors of baked apple, vanilla cream and woodspice are endearing. Long and flavorful on the finish, and not overoaked. A serious Chardonnay to drink now.\n",
      "Actual: Argentina, predicted: Argentina\n",
      "\n",
      "Dark golden in color, this late-harvest Riesling, which was allowed to develop botrytis after two October 2011 storms, has knockout, sweet honey and apricot goodness from start to finish. It's round and concentrated, and it has 12.9% residual sugar. Incredible on its own, this will also pair well with peach- and pineapple-based desserts, foie gras and blue cheeses.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Sweeter, more developed aromas of caramel, candied red apple, Boston baked beans and honeydew develop on the nose, while the mouth shows more typical Chard notes of baked apple and hazelnut butter. A touch round and flabby, but ends with a long, delicious, vanilla-kissed finish.\n",
      "Actual: US, predicted: South Africa\n",
      "\n",
      "This limited-production, aged wine incorporates 8% Merlot, sourcing grapes from several vineyards across the Napa Valley. Blueberry pie and sweet tobacco rise to the fore around an elegantly crafted structure, while soft, firm tannins provide just enough grip to stay juicy and compelling on the palate. It finishes with notes of chocolate, caramel and baking spice.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Smells grassy, jumpy and foxy, and while it sports a decent feel on the palate, it's herbal and tomatoey in terms of flavor, with a vegetal undertone. Green and oaky on the finish.\n",
      "Actual: Argentina, predicted: Argentina\n",
      "\n",
      "A rounded style of Sauvignon Blanc, but one that doesn't lose sight of its herbaceous element. So there is crispness, a vivacious acidity, but also flavors of creamy apple and ripe pear. To drink this year.\n",
      "Actual: Austria, predicted: France\n",
      "\n",
      "A blend of Sangiovese and Merlot, this delightful red has fruity aromas of wild berry and plum. The easy-drinking palate offers black cherry and a spicy note of clove alongside polished tannins. It's made to be drunk young, so enjoy soon.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "This wine brings aromas of blackberry, dates and spice. The palate displays abundant cherry flavors with lightly chalky tannins.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "A Négrette-based wine, this is full of red berry flavors and that leathery, polished character that is typical of the grape. It has plenty of acidity as well as a tight, tannic character. The wine will always be tannic, so it is ready to drink now.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "This is a concentrated, balanced, sweetly juicy wine, benefiting from wood and ripe black fig and plum flavors. It has fine ripe tannins that support the freshly juicy fruits. Ready to drink, but will age over 2–3 years.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "Aromas of rose, blue flower, wild berry and a hint of forest floor lead the way along with a balsamic note. The extremely ripe palate offers raspberry compote, licorice and a green note of powdered sage alongside bracing tannins that leave a gripping, drying finish. Give the tannins a few years to unwind then drink.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "This is elaborate, but too soft for a great Napa Cabernet. That absence of structure accentuates its ripeness, giving it tastes of candied cherry and licorice. On the plus side, it's dry and smooth, with lots of smoky new French oak. Drink now.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Aromas of spiced fig, resin, tobacco, grilled sage and underbrush lead the nose. The focused palate offers dark cherries, baking spices and savory herbs alongside velvety tannins and fresh acidity. A smoky mineral note heralds the close. Drink through 2021.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "Fresh and crisp, this is a wine that has little flavor and only the thinest palate. It is bright to drink now.\n",
      "Actual: Portugal, predicted: France\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "LIMIT = 30  # How many results to display\n",
    "SHOW_ONLY_WRONG = False # If set to true, will only show the wrongly classified samples\n",
    "\n",
    "with open('preprocessed_datasets/test.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        if i > LIMIT:\n",
    "            break\n",
    "        sentence = row[2]\n",
    "        real_value = row[COLUMNS_STOI[CURRENT_LABEL]]\n",
    "        pred_value = predict_class(model, sentence)\n",
    "        if not SHOW_ONLY_WRONG or real_value != LABEL.vocab.itos[pred_value]:\n",
    "            print(sentence)\n",
    "            print(\"Actual: \" + str(real_value) + \", predicted: \" + str(LABEL.vocab.itos[pred_value]) + \"\\n\")\n",
    "        i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN experiments\n",
    "\n",
    "We also implemented a multi-class RNN as it usually works well on text analysis, because of the sequential nature of text. However, it turned out that it was not performing as well as our CNN described above, and was much longer to train. If you want to try to run it by yourself (beware: the training can take several hours), you'll have to change a few things in the code above - look for the comments about RNN.\n",
    "\n",
    "The train and evaluate functions are similar to those of the CNN, the main difference being the text length being taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNN(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (index, batch) in enumerate(iterator):\n",
    "        print(index/len(iterator))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.description\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.province)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.province)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluateRNN(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.description\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.province)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.province)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = trainRNN(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluateRNN(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'wine-prediction-model.pt')\n",
    "    \n",
    "    print('Epoch: ' + str(epoch+1.02) + ' | Epoch Time: ' + str(epoch_mins) + 'm '+ str(epoch_secs) + 's')\n",
    "    print('\\tTrain Loss: ' + str(train_loss) + ' | Train Acc: ' + str(train_acc*100) + '%')\n",
    "    print('\\tVal. Loss: ' + str(valid_loss) + ' |  Val. Acc: ' + str(valid_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below you can find the definition of our RNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)   \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
