{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine classification project\n",
    "\n",
    "This is a NLP and deep learning project using `spacy`, `pytorch` and `torchtext`, aiming to retrieve information about a wine based on short text reviews, written by a taster.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The data we're looking to guess are the **country** of production, the  **province** of production, and the **grape variety**.  \n",
    "As a side objective, we show that on this dataset we can retrieve with a great accuracy the **name of the taster**, only from a review they have written.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset contain data scraped from [WineEnthusiast](https://www.winemag.com/?s=&drink_type=wine), and is hosted on [this kaggle page](https://www.kaggle.com/zynicide/wine-reviews#winemag-data-130k-v2.csv). Each example contains a written review of a wine, an various data about this wine like the country and province of production, the grape variety, the winery, the name and twitter handle of the taster, a general grade and a price index.\n",
    "\n",
    "## What we'll do\n",
    "\n",
    "We'll perform the following steps: \n",
    "- Load and clean the data\n",
    "- Setup the training, validation and testing datasets\n",
    "- Setup pre-trained word embeddings\n",
    "- Create a CNN to classify our data\n",
    "- Write a training routine\n",
    "- Test our model\n",
    "\n",
    "In appendix, you'll also find:\n",
    "- Helpers to analysis our model performance and diagnose misclassifications\n",
    "- Our initial RNN implementation, which was not performing as well as our CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 2753 # We always use the same seed for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(\n",
    "    tokenize= 'spacy'\n",
    "#     include_lengths=True # Uncomment for RNN (see appendix)\n",
    ")\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load `torch` and `torchtext`, and setup our fields for `torchtext`. Note that we indicate we're going to use `spacy` as our tokenizer. You need to have spacy installed for this to work, as well as downloading an english language model. `torchtext` expects this model to be called `en`, so you might have to rename it.\n",
    "\n",
    "### Load and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1277 rows\n",
      "Number of classes before cutting: 44\n",
      "Original number of rows: 129909\n",
      "Rows after cutting: 128632\n",
      "Classes kept: ['Italy', 'Portugal', 'US', 'Spain', 'France', 'Germany', 'Argentina', 'Chile', 'Australia', 'Austria', 'South Africa', 'New Zealand', 'Israel', 'Greece', 'Canada']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "CURRENT_LABEL = 'country' # Column we're currently trying to guess. Change this to any of the above columns.\n",
    "\n",
    "# String to int relation between column name and column index, to access them easily\n",
    "COLUMNS_STOI = {\n",
    "    'country': 1, \n",
    "    'province': 6, \n",
    "    'taster_name': 9,\n",
    "    'variety': 12,\n",
    "}\n",
    "\n",
    "MIN_SAMPLE_NUMBER = 150\n",
    "\n",
    "column_number = COLUMNS_STOI[CURRENT_LABEL]\n",
    "\n",
    "with open('datasets/winemag-data-130k-v2.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    lines_uncontrolled = []\n",
    "    counts = {}\n",
    "\n",
    "    for row in reader:\n",
    "        if not row[column_number]:\n",
    "            # Skip the row if it doesn't have the current label\n",
    "            continue\n",
    "        if CURRENT_LABEL == 'province':\n",
    "            # Fix the issue where \"Bordeaux\" is also sometimes called \"Burgundy\" (they are the same thing)\n",
    "            if province == \"Burgundy\":\n",
    "                row[6] = \"Bordeaux\"\n",
    "        # Keep a count of each label occurence\n",
    "        if not row[column_number] in counts.keys():\n",
    "            counts[row[column_number]] = 1\n",
    "        else:\n",
    "            counts[row[column_number]] += 1\n",
    "        lines_uncontrolled.append(row)\n",
    "        \n",
    "lines = []\n",
    "\n",
    "# Remove the rows where the label is too rare\n",
    "for row in lines_uncontrolled:\n",
    "    if counts[row[column_number]] >= MIN_SAMPLE_NUMBER:\n",
    "        lines.append(row)\n",
    "    \n",
    "                      \n",
    "print(\"Removed \" + str(len(lines_uncontrolled) - len(lines)) + \" rows\")\n",
    "\n",
    "print(\"Number of classes before cutting:\", len(counts.keys()))\n",
    "print(\"Original number of rows:\", len(lines_uncontrolled))    \n",
    "print(\"Rows after cutting:\", len(lines))\n",
    "print(\"Classes kept:\", [k for k in counts.keys() if counts[k] >= MIN_SAMPLE_NUMBER])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset sometimes lacks data, so we need to make sure we only select the rows where the data we're looking at is present. We also want to keep only the examples for which we have enough data : for instance, if a variety is too rare in the dataset, we won't be able to determine rules to understand what this variety consists in. We can finetune the threshold with `MIN_SAMPLE_NUMBER`. We set it to `150`, which is `1/1000` of the total dataset size.\n",
    "\n",
    "### Train, validation and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 64315\n",
      "Validation set size: 25727\n",
      "Test set size: 38589\n",
      "Train set sample: ['60920', 'US', 'Serious Cabernet, rich and complex and full bodied, made from Knights Valley and Alexander Valley fruit, with a few grapes from Atlas Peak and Mount Veeder. Dense and tannic now, but high toned, with waves of black currants, black cherries and oak. A good price for a Cabernet of this quality. Drink nowâ€“2012.', 'Grand Reserve', '91', '30.0', 'California', 'Sonoma County', 'Sonoma', '', '', 'Kendall-Jackson 2007 Grand Reserve Cabernet Sauvignon (Sonoma County)', 'Cabernet Sauvignon', 'Kendall-Jackson']\n"
     ]
    }
   ],
   "source": [
    "TEST_SET_SIZE = .3\n",
    "VALIDATION_SET_SIZE = .2\n",
    "\n",
    "indices = list(range(1, len(lines)))\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "first_split_index = int(TEST_SET_SIZE * len(lines))\n",
    "second_split_index = int((TEST_SET_SIZE+VALIDATION_SET_SIZE) * len(lines))\n",
    "\n",
    "test_indices = indices[:first_split_index]\n",
    "validation_indices = indices[first_split_index:second_split_index]\n",
    "train_indices = indices[second_split_index:]\n",
    "\n",
    "train_set = [lines[k] for k in train_indices]\n",
    "test_set = [lines[k] for k in test_indices]\n",
    "validation_set = [lines[k] for k in validation_indices]\n",
    "\n",
    "print(\"Train set size:\", len(train_set))\n",
    "print(\"Validation set size:\", len(validation_set))\n",
    "print(\"Test set size:\", len(test_set))\n",
    "print(\"Train set sample:\", train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset in train, validation and test. We choose the size of the validation dataset to be 20% of the total size, and the test set to be 30%, leaving 50% for the training.\n",
    "\n",
    "We then write these sets to csv files so we can load them afterwards. Note that we're using the `csv` library to write, because our wine reviews contain commas, so we need to be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir('preprocessed_datasets')\n",
    "except OSError:\n",
    "    # It means the directory already exists, so let's just continue\n",
    "    pass\n",
    "    \n",
    "\n",
    "with open('preprocessed_datasets/train.csv', 'w') as train_file:\n",
    "    writer = csv.writer(train_file)\n",
    "    writer.writerows(train_set)\n",
    "    \n",
    "with open('preprocessed_datasets/test.csv', 'w') as test_file:\n",
    "    writer = csv.writer(test_file)\n",
    "    writer.writerows(test_set)\n",
    "with open('preprocessed_datasets/validation.csv', 'w') as validation_file:\n",
    "    writer = csv.writer(validation_file)\n",
    "    writer.writerows(validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the datasets\n",
    "\n",
    "Then we'll setup the datasets so they can be used by `torchtext`. Here, we tell the library what the lines contains, and what data we want to use. We can select here the label we want to be working on, by setting it to `LABEL`, otherwise we leave it to `None`.\n",
    "\n",
    "The `description` field, which contains the reviews, will always be set to `TEXT`: this is the field on which we're going to do some NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the label you want to predict as `LABEL`, all the other ones to `None`.\n",
    "tv_datafields = [(\"id\", None),\n",
    "                 (\"country\", LABEL),\n",
    "                 (\"description\", TEXT),\n",
    "                 (\"designation\", None),\n",
    "                 (\"points\", None),\n",
    "                 (\"price\", None),\n",
    "                 (\"province\", None),\n",
    "                 (\"region_1\", None),\n",
    "                 (\"region_2\", None),\n",
    "                 (\"taster_name\", None),\n",
    "                 (\"taster_twitter_handle\", None),\n",
    "                 (\"title\", None),\n",
    "                 (\"variety\", None),\n",
    "                 (\"winery\", None)]\n",
    "\n",
    "trn, vld, tst = data.TabularDataset.splits(path='preprocessed_datasets',\n",
    "                                     format=\"csv\",\n",
    "                                     train= 'train.csv',\n",
    "                                     validation='validation.csv',\n",
    "                                     test='test.csv',\n",
    "                                     fields=tv_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup word embedding\n",
    "\n",
    "Now we'll use pretrained word embeddings to improve the accuracy and speed up the training of our models.  \n",
    "We'll build ourselves a vocabulary of the words encountered in the reviews (and in the labels), but as the reviews are quite big, we'll only keep the words common enough. For this we can set a limit on the number of words in our vocabulary. This is not necessary for the labels, because the vocabulary for them is much smaller.\n",
    "\n",
    "**Beware :** `glove.6B.100d` is a library of pretrained vectors. It weights around **800M** and if you don't have it installed, running the following cell will download it. Make sure you have a good connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews vocab length: 25002\n",
      "Labels vocab length: 15\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(trn,\n",
    "                 max_size=MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",  # CAREFUL: this will download ~800M of data\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "print(\"Reviews vocab length:\", len(TEXT.vocab))\n",
    "print(\"Labels vocab length:\", len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we get `25 002` and not `25 000` as our TEXT vocab lenght. This is because `torchtext` adds two reserved tokens: it replaces the word out of our vocab with a `<unk>` (unknown) token, and adds padding so the samples are all the same size with a `<pad>` token.\n",
    "\n",
    "We can check the most common words in our reviews vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 218513), ('.', 175333), ('and', 172093), ('of', 84913), ('the', 83112), ('a', 78408), ('with', 57539), ('is', 48552), ('wine', 39830), ('-', 36812), ('this', 36108), ('in', 29999), ('flavors', 29798), ('to', 27640), ('The', 26346), (\"'s\", 25521), ('fruit', 24620), ('It', 21413), ('it', 21153), ('on', 21067), ('This', 20297), ('that', 19687), ('palate', 19062), ('aromas', 17373), ('acidity', 17111), ('finish', 16994), ('tannins', 15099), ('from', 14989), ('but', 14604), ('cherry', 14193)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the most common word is a comma, which explains why we had to be careful with our csv reading and writing.\n",
    "\n",
    "Now we'll setup iterators, which will allow us to iterate through batches of our training, validation and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # If you have cuda support, this will make sure you're using if for training\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (trn, vld, tst), \n",
    "    batch_size = BATCH_SIZE,\n",
    "#     sort_within_batch=True, # Uncomment for RNN (see appendix), because batches need to be sorted\n",
    "    sort_key=lambda x: len(x.description), \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we sort our data according to the length of the review. This is because we need to add some padding to the reviews to make sure all the samples in a batch are of the same size. Gathering samples of same size close together will ensure we won't have to add too much padding, which will speed up the process a bit.\n",
    "\n",
    "### Creating the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        text = text.permute(1, 0)        \n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__` function we define the architecture of our model. \n",
    "- First we have an **embedding layer** (our input vectors are one-hot vector and are sparse, this will turn them into smaller, non-sparse vector)\n",
    "- Several **convolution layers** : convolution on text is a bit specific, we wrote a little bit more about it in our pdf (in French). Basically, it performs convolution a bit like we would do on images, but instead of layers we use n-grams. Then they all use **ReLU** as an activation function, and then use **max pooling**.\n",
    "- Finally a **linear layer**, of same output size as our number of classes, so we can perform classification\n",
    "- Note we're using **dropout**: this is a technique to avoid overfitting, by randomly setting some node to 0 at each forward pass.\n",
    "\n",
    "Next we'll have to choose the parameters of this architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMENSION = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIMENSION, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `INPUT_DIM` and `OUTPUT_DIM` are based on our data.\n",
    "- The embedding dimension `EMBEDDING_DIM` is fixed by the pretrained data we've loaded, so we have to keep this one at 100.\n",
    "- We can choose `N_FILTER` and `FILTER_SIZES` freely, as well as the dropout rate `DROUPOUT`.\n",
    "\n",
    "We can now use our pre-trained embeddings to setup initial values in our embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0737, -1.4165,  0.7548,  ..., -1.6059, -0.2473,  0.2487],\n",
       "        [-0.0412, -0.6711,  0.8314,  ..., -1.2042,  0.2975, -0.3076],\n",
       "        [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
       "        ...,\n",
       "        [ 0.1787,  0.0940, -0.6176,  ..., -0.1955, -0.3778, -0.0580],\n",
       "        [ 0.0252, -0.9636, -0.2277,  ..., -2.2039,  0.3247,  0.5036],\n",
       "        [-1.5420,  0.4095,  0.0563,  ...,  0.4985,  1.0879, -0.5282]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the pretrained vectors did not contain the `<unk>` and `<pad>` tokens, so we assign them all-zeros token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now we have everything defined, we can train our model.\n",
    "\n",
    "We choose Adam as our optimizer (the nice thing about Adam is that we don't have to select a learning rate, as we would need with stochastic gradient descent).  \n",
    "We also need to choose a loss function. Here we use `CrossEntropyLoss` from `pytorch`, which is for when a sample belongs to exclusively one class (this is our case, as each wine only belongs to one country, one province, has only one writer...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define an accuracy function. As we are doing multi-class classification, we can use the proportion of correctly classified samples in a batch, in other words: on each sample, we choose the label with the max probability, and then we check on the batch what is the proportion of correctly classified labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our training and evaluating functions, which will repectively train the model and evaluate accuracy batch after batch.\n",
    "\n",
    "We are always using the `description` field (review text) as an input, but we can take varying outputs depending on what label we're experimenting on, so we need to get this one back with `getattr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.description)\n",
    "        \n",
    "        loss = criterion(predictions, getattr(batch, CURRENT_LABEL))\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, getattr(batch, CURRENT_LABEL))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.description)\n",
    "            \n",
    "            loss = criterion(predictions, getattr(batch, CURRENT_LABEL))\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, getattr(batch, CURRENT_LABEL))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a helper function to keep track of time during training, so we can compare how fast our different models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to run the training!\n",
    "\n",
    "We choose the number of epochs we want to run the model on, and when we get better results, we save the model in a separate file to make sure we don't lose it as this step can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Epoch Time: 2m 30s\n",
      "\tTrain Loss: 1.038166518857823 | Train Acc: 68.35233261929223%\n",
      "\tVal. Loss: 0.6452360872309006 |  Val. Acc: 79.10355218310853%\n",
      "Epoch: 2 | Epoch Time: 2m 43s\n",
      "\tTrain Loss: 0.6372991372696796 | Train Acc: 79.22780166811017%\n",
      "\tVal. Loss: 0.5362838631245628 |  Val. Acc: 81.66897408108214%\n",
      "Epoch: 3 | Epoch Time: 2m 42s\n",
      "\tTrain Loss: 0.5159955355065379 | Train Acc: 82.80443650573048%\n",
      "\tVal. Loss: 0.4701322091752617 |  Val. Acc: 83.89618129872564%\n",
      "Epoch: 4 | Epoch Time: 2m 40s\n",
      "\tTrain Loss: 0.43658111817504636 | Train Acc: 85.01773442201946%\n",
      "\tVal. Loss: 0.45510196037108624 |  Val. Acc: 84.40134397786649%\n",
      "Epoch: 5 | Epoch Time: 2m 37s\n",
      "\tTrain Loss: 0.3796428862347532 | Train Acc: 86.84245614863154%\n",
      "\tVal. Loss: 0.4365081242216167 |  Val. Acc: 84.96123055617014%\n",
      "Epoch: 6 | Epoch Time: 2m 34s\n",
      "\tTrain Loss: 0.33618637588783284 | Train Acc: 88.08689602571933%\n",
      "\tVal. Loss: 0.4432896591389357 |  Val. Acc: 85.12435343431596%\n",
      "Epoch: 7 | Epoch Time: 2m 33s\n",
      "\tTrain Loss: 0.30325687466124396 | Train Acc: 89.38353781676412%\n",
      "\tVal. Loss: 0.4351215787343125 |  Val. Acc: 85.32264274151171%\n",
      "Epoch: 8 | Epoch Time: 2m 33s\n",
      "\tTrain Loss: 0.273372920420929 | Train Acc: 90.14379901079396%\n",
      "\tVal. Loss: 0.4452541205494558 |  Val. Acc: 85.48206388950348%\n",
      "Epoch: 9 | Epoch Time: 2m 34s\n",
      "\tTrain Loss: 0.2453828823062318 | Train Acc: 91.08103549895596%\n",
      "\tVal. Loss: 0.46568708670376546 |  Val. Acc: 85.56757383975223%\n",
      "Epoch: 10 | Epoch Time: 2m 35s\n",
      "\tTrain Loss: 0.2211702081249721 | Train Acc: 91.99210515069724%\n",
      "\tVal. Loss: 0.4707226526010689 |  Val. Acc: 85.65703230117684%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'wine-prediction-model.pt')\n",
    "    \n",
    "    print('Epoch: ' + str(epoch+1) + ' | Epoch Time: ' + str(epoch_mins) + 'm '+ str(epoch_secs) + 's')\n",
    "    print('\\tTrain Loss: ' + str(train_loss) + ' | Train Acc: ' + str(train_acc*100) + '%')\n",
    "    print('\\tVal. Loss: ' + str(valid_loss) + ' |  Val. Acc: ' + str(valid_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the results\n",
    "\n",
    "Now we have trained the model, we can use the test samples we have left aside to test its perfomance on unknown samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4347682754149287 | Test Acc: 85.83219490241055%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('wine-prediction-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print('Test Loss: ' + str(test_loss) + ' | Test Acc: '+ str(test_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the experiment you're running, you can get various results at this step. We kept in our pdf a track of the results we could obtain here.\n",
    "\n",
    "### Live testing\n",
    "\n",
    "To play a bit more with the model, we can use `spacy` to classify in live some reviews :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_class(model, sentence, min_len = 4):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    max_preds = preds.argmax(dim = 1)\n",
    "    return max_preds.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, you can put any review in the description, and check how the model classifies it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is: 1 = France\n"
     ]
    }
   ],
   "source": [
    "description = \"This cooperative, based in AÃ¿, has benefited from the fine Pinot Noir in the village to produce a ripe red fruited wine. With balanced acidity and a soft aftertaste, it is ready to drink.\"\n",
    "pred_class = predict_class(model, description)\n",
    "print('Predicted class is: ' + str(pred_class) + ' = ' + str(LABEL.vocab.itos[pred_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "We also provide a few things that are not directly linked to our results above but we used during our work.  \n",
    "\n",
    "### Results exploration\n",
    "\n",
    "To check how our model was performing, as especially in what cases it didn't perform well, we used the following script. It allows us to see a number of wrongly classified samples. This is for instance how we found out that **Burgundy** was also called **Bordeaux** in the dataset, which led to lots of classification errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still showing its tannins, this wine is developing well. It is relatively light in texture, the sweet berry fruits balanced with a layer of acidity.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "A unique blend of fermenting orange, aging white flowers, dried apples and a musky sandalwood show on the nose of this wine. The palate is simultaneously rich, sour and creamy, with tangerine and banana flavors.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Sweet tobacco and overripe cherry open the nose of this thick, jammy Amarone. The wine exhibits a syrupy, bold mouthfeel with lingering tones of smoke, beef jerky and spice on the finish.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "Mineral aromas of gravel, graphite and crushed slate show on the nose of this bottling, leading into baked black plum and oak notes. It's a refreshing example from an appellation that tends toward richer, jammy styles. The palate offers raspberry and dried thyme flavors, with a touch of eucalyptus.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Aromas of plum, wild herbs and tobacco are mature and suggest that this is ready to drink. In the mouth, this is medium-bodied, with clarity and a sense of freshness. Plum, berry and cherry flavors finish in harmony. Drink through 2020.\n",
      "Actual: Spain, predicted: Spain\n",
      "\n",
      "This is raisiny and jammy on the nose. That's followed by a scratchy palate with rough tannins. Roasted grapy flavors are just pleasant enough, while a gravelly finish is ruled by residual hard tannins.\n",
      "Actual: Spain, predicted: Chile\n",
      "\n",
      "Alluring aromas of blackberry and barrel spice lead to ripe, full-bodied black-fruit flavors, showing beautiful depth and a long finish. It packs a hefty punch while never losing its sense of balance.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "This opens with aromas of ripe black plum, scorched soil, toasted oak and roasted coffee bean. The dense ripe palate offers dried cherry, clove and espresso with chewy tannins. Drink through 2019 to catch the remaining fruit.\n",
      "Actual: Italy, predicted: Italy\n",
      "\n",
      "On the lean side, this is a dry, tannic wine with more structure than flesh. It's firm, with a strong sense of wood aging followed by some acidity. It could soften in 3â€“4 years.\n",
      "Actual: Portugal, predicted: France\n",
      "\n",
      "Creamy and tartly acidic, with sour pineapple candy, pear, buttered popcorn and vanilla flavors. Made in a popular style that will appeal to fans of oaky Chards.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "This is an attractively fruity wine that has just the right tannic structure, solid berry fruits and good acidity. It's a wine that is developing well and is ready to drink now.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "This is a pretty rose hue, and follows in a light, tart style. Despite its apparent simplicity, it shows surprising depth of flavor, highlighted with fresh strawberries and Bing cherries. There's a touch of Juicy Fruit gum also, and the wine should be consumed now through 2020.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Nervy and tight smelling, this has rubber, black plum and berry. The palate feels a touch grabby, with roasted, slightly bitter flavors of dark chocolate, espresso and blackberry. The finish has plenty of oak flavor, with a leafy, herbal hint.\n",
      "Actual: Argentina, predicted: Argentina\n",
      "\n",
      "Raspberry and cherry fruit flavors flood the mouth on this Zin, making it instantly delicious. The superripeness shows on the finish, where chocolate-covered raisin notes show up. With complex, gentle tannins and some heat from alcohol, it's drinking well now.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "This smells dry and leafy, with a bacon note. It feels lively and edgy, with berry, currant and oak spice in its flavor profile. It finishes fairly tannic and warm, with a rubbery strength.\n",
      "Actual: Chile, predicted: Spain\n",
      "\n",
      "On the south side of the village of Chablis, the Vaillons vineyard is on the cool, left bank of the river Serein. It is fruity with a creamy texture and a line of steely acidity that often marks out the premier crus, giving this wine the chance to age. Drink from 2017.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "A finely balanced wine that combines rich red fruit flavors with acidity, a slight tang from the spirit and a feeling of warmth and roundness. It finishes with an almond note and fresh acidity.\n",
      "Actual: Portugal, predicted: France\n",
      "\n",
      "Winemaker: Bruce Jack. A curious blend of 83% Tinta Barocca, 8.5% Barbera and 8.5% Monastrell, this is winemaker Bruce Jack's play on considering your, and his, \"comfort zone.\" It's rich, robust and full, brimming with ripe black berries, boysenberry preserves, Baker's chocolate, tree bark, black tea and dried iris. Despite all this richness, there's remarkable freshness and mineral lift to the palate, as well as velvety tannins to lend supporting structure. Overall, it's big and bold, but balanced and promising; delicious now, but try after 2021 to see added maturity.\n",
      "Actual: South Africa, predicted: South Africa\n",
      "\n",
      "This is a rich and full-bodied wine. While it is certainly packed with crunchy cherry flavors, it also has a more tannic and structured side giving it a firm texture to back up the fruitiness. The aftertaste is juicy and ripe.\n",
      "Actual: France, predicted: France\n",
      "\n",
      "Generic berry aromas come with herbal, earthy accents and a lactic note. The palate on this Malbec-led blend is grabby, while flavors of saline, roasted plum and berry finish with chocolaty weight.\n",
      "Actual: Argentina, predicted: Argentina\n",
      "\n",
      "This is complex, delicious, bold and tannic, bringing the big structure that is expected without being heavy handed. It offers concentrated blackberry and fig aromas, richly jammy flavors that stay dry and a tannic but not tough texture.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Zesty Monterey acidity gives life to this Pinot and lifts it above being a mere candy bar. Yes, it's sweetish and direct in cherries, raspberries and cola, but that tang makes it easy to enjoy.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "This youthful wine might just be holding some of its nuances back, but for now it's singularly minded in caramel and toffee with a baked-apple pie vibe, wrapped in generous oak.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Strong aromas of cassis, cocoa nibs, fresh mint sprigs, black currant leaf and licorice are the first things you experience with this wine. After that, the creamy mouth provides loads of black berry, plum and anise flavors that stay through the finish. A firmly structured and well-balanced Bordeaux-style blend.\n",
      "Actual: South Africa, predicted: South Africa\n",
      "\n",
      "Fresh green herbs and lime zest lend vibrance to this lighter-bodied bottling from Wiemer's 2015 vintage. White grapefruit and citrus are piercing and spry, finishing with a delightful edge of salt and crushed-stone. Drinks beautifully now but should develop well through 2028.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "This carries true-to-variety flavors of peppery blackberry fruit, here cloaked in coffee and toast from aging in 40% new French and American oak barrels. The lemony acids contribute to the overall balance and ageworthy structure.\n",
      "Actual: Canada, predicted: US\n",
      "\n",
      "Marred by unripe asparagus notes, this Syrah is tough to like despite its smooth tannins and some good blackberry and chocolate fruit.\n",
      "Actual: US, predicted: US\n",
      "\n",
      "Fresh and zesty, with wet stones and talcum powder upfront, followed by apple and gardenia in the mouth. It's light-bodied and slightly off-dry with a short-to-medium finish redolent of white flowers. Drink now.\n",
      "Actual: US, predicted: Australia\n",
      "\n",
      "Ripe and weighty, this is a rich wine from the Pfaffenberg vineyard in Krems. It has spice as well as perfumed white fruits, a sense of structure and concentration. It feels warm with peach and white fruit flavors likely to develop along with acidity over the next 3â€“4 years.\n",
      "Actual: Austria, predicted: Austria\n",
      "\n",
      "Although it's young, this wine has seen some time in oak, which has given it a ripe fruity character balanced by toast. It's rich and full with balancing acidity and a spicy aftertaste. It needs to age a few months, so drink from 2016.\n",
      "Actual: Portugal, predicted: Portugal\n",
      "\n",
      "This is beautifully lilting in preciously defined aromas of rose petal and wild strawberry. From there, it's all subtlety and ethereal elegance. The wine is restrained, nurtured in a basket of nutmeg and graham cracker, as well as freshly packed mushroomy earth. This wine is a stunner right out of the glass, but is sure to continue its fine course through 2022â€“2025.\n",
      "Actual: US, predicted: US\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "LIMIT = 30  # How many results to display\n",
    "SHOW_ONLY_WRONG = False # If set to true, will only show the wrongly classified samples\n",
    "\n",
    "with open('preprocessed_datasets/test.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        if i > LIMIT:\n",
    "            break\n",
    "        sentence = row[2]\n",
    "        real_value = row[COLUMNS_STOI[CURRENT_LABEL]]\n",
    "        pred_value = predict_class(model, sentence)\n",
    "        if not SHOW_ONLY_WRONG or real_value != LABEL.vocab.itos[pred_value]:\n",
    "            print(sentence)\n",
    "            print(\"Actual: \" + str(real_value) + \", predicted: \" + str(LABEL.vocab.itos[pred_value]) + \"\\n\")\n",
    "        i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN experiments\n",
    "\n",
    "We also implemented a multi-class RNN as it usually works well on text analysis, because of the sequential nature of text. However, it turned out that it was not performing as well as our CNN described above, and was much longer to train. If you want to try to run it by yourself (beware: the training can take several hours), you'll have to change a few things in the code above - look for the comments about RNN.\n",
    "\n",
    "The train and evaluate functions are similar to those of the CNN, the main difference being the text length being taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNN(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (index, batch) in enumerate(iterator):\n",
    "        print(index/len(iterator))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.description\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.province)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.province)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluateRNN(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.description\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.province)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.province)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = trainRNN(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluateRNN(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'wine-prediction-model.pt')\n",
    "    \n",
    "    print('Epoch: ' + str(epoch+1.02) + ' | Epoch Time: ' + str(epoch_mins) + 'm '+ str(epoch_secs) + 's')\n",
    "    print('\\tTrain Loss: ' + str(train_loss) + ' | Train Acc: ' + str(train_acc*100) + '%')\n",
    "    print('\\tVal. Loss: ' + str(valid_loss) + ' |  Val. Acc: ' + str(valid_acc*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below you can find the definition of our RNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)   \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
